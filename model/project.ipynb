{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNk+yYYJc+6jCr8t+AeMloY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JBo1yVvr8T8P","executionInfo":{"status":"ok","timestamp":1705327383712,"user_tz":-480,"elapsed":22144,"user":{"displayName":"陳柏丞","userId":"03926144741521813207"}},"outputId":"c9bc0367-925a-4bf6-b32c-2742f9186abe"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# project\n"],"metadata":{"id":"8gAfzVZ_HK7V"}},{"cell_type":"code","source":["import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()\n","import numpy as np\n","import random\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from collections import deque\n","from pandas_datareader import data as pdr\n","import  yfinance as yf\n","import math\n","import json\n","from sklearn.preprocessing import StandardScaler\n","!pip install yfinance --upgrade --no-cache-dir\n"],"metadata":{"id":"GEaYgkPcGwAf","executionInfo":{"status":"ok","timestamp":1705327462306,"user_tz":-480,"elapsed":29857,"user":{"displayName":"陳柏丞","userId":"03926144741521813207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"fc508b89-4ec9-4501-db03-7b9b8064c2ed"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.35)\n","Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.23.5)\n","Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n","Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n","Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n","Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n","Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.3.post1)\n","Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.0)\n","Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.0)\n","Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n","Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2023.11.17)\n"]}]},{"cell_type":"code","source":["yf.pdr_override()\n","data_source = \"yfinance\"\n","data_name = \"^TWII\"\n","\n","if data_source == \"csv\":\n","  df_full = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/project/tfe-tx00-2023.csv').reset_index()\n","  # df_full = df_full[::100]\n","  # df_train = df_full[:2000]\n","  # df_test = df_full[2000:]\n","elif data_source == \"yfinance\":\n","  df_train = pdr.get_data_yahoo(data_name, start=\"2019-01-01\", end=\"2022-12-31\").reset_index()\n","  df_test = pdr.get_data_yahoo(data_name, start=\"2023-01-01\").reset_index()\n"],"metadata":{"id":"MR4GtAxfHpuM","executionInfo":{"status":"ok","timestamp":1705327480760,"user_tz":-480,"elapsed":18460,"user":{"displayName":"陳柏丞","userId":"03926144741521813207"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"30a09534-e4c5-4a57-cf86-a644852b77cf"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["[*********************100%%**********************]  1 of 1 completed\n","[*********************100%%**********************]  1 of 1 completed\n"]}]},{"cell_type":"code","source":["def epsilon_decay_cal(epsilon = 0.5, epsilon_min = 0.01, target_iterations = 100000) :\n","    epsilon = epsilon\n","    epsilon_min = epsilon_min\n","    target_iterations = target_iterations\n","\n","    epsilon_decay = (epsilon_min / epsilon) ** (1 / target_iterations)\n","    print(f\"需要 {target_iterations} 次迭代才會使 epsilon 降到 {epsilon_min}\")\n","\n","    return epsilon_decay"],"metadata":{"id":"i5XXxKpxBiQd","executionInfo":{"status":"ok","timestamp":1705327480761,"user_tz":-480,"elapsed":6,"user":{"displayName":"陳柏丞","userId":"03926144741521813207"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# MACD　function\n","def to_MACD(close, long = 26, short = 12, c = 9 ) :\n","    close_series = pd.Series(close)\n","    close_emaL = close_series.ewm(span=12, adjust=False).mean()\n","    close_emaS = close_series.ewm(span=26, adjust=False).mean()\n","    dif = close_emaL - close_emaS\n","    macd = dif.ewm(span=9, adjust=False).mean()\n","    MACD = dif - macd\n","    MACD_list = MACD.tolist()\n","\n","    return MACD_list"],"metadata":{"id":"W71VK3AR6iUU","executionInfo":{"status":"ok","timestamp":1705327480761,"user_tz":-480,"elapsed":5,"user":{"displayName":"陳柏丞","userId":"03926144741521813207"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class Agent:\n","    def __init__(self, state_size, window_size, trend, buy_trend, skip, batch_size, train_MACD, buy_MACD, MACD_enable):\n","\n","        self.state_size = state_size\n","        self.window_size = window_size\n","        self.half_window = window_size // 2\n","        self.trend = trend\n","        self.buy_trend = buy_trend\n","        self.skip = skip\n","        self.action_size =  19            ### action size\n","        self.action_size_half = self.action_size // 2  ###  -  1\n","        self.batch_size = batch_size\n","        self.memory = deque(maxlen=10000)\n","        self.inventory = []\n","        self.train_MACD = train_MACD\n","        self.buy_MACD = buy_MACD\n","        self.MACD_enable = MACD_enable\n","        self.returns_list = []\n","\n","        # self.gamma = 0.99\n","        # self.epsilon = 0.5\n","        # self.epsilon_min = 0.01\n","        # self.epsilon_decay = 0.999\n","\n","        self.gamma = 0.98\n","        self.epsilon = 0.9\n","        self.epsilon_min = 0.01\n","        new_epsilon_decay = epsilon_decay_cal( epsilon = self.epsilon,\n","                             epsilon_min = self.epsilon_min,\n","                             target_iterations = len(self.trend) * 20)\n","        self.epsilon_decay = new_epsilon_decay\n","\n","        tf.reset_default_graph()\n","        self.sess = tf.InteractiveSession()\n","        self.X = tf.placeholder(tf.float32, [None, self.state_size])\n","        self.Y = tf.placeholder(tf.float32, [None, self.action_size])\n","        hidden1 = tf.layers.dense(self.X, 256, activation=tf.nn.relu)\n","        self.logits = tf.layers.dense(hidden1, self.action_size)\n","        self.cost = tf.reduce_mean(tf.square(self.Y - self.logits))\n","        self.optimizer = tf.train.AdamOptimizer(1e-5).minimize(\n","            self.cost\n","        )\n","        self.sess.run(tf.global_variables_initializer())\n","        self.saver = tf.train.Saver()\n","\n","    ### model save and load\n","    def save_model(self, path):\n","        self.saver.save(self.sess, path)\n","        print(\n","            \"Save current model\"\n","          )\n","\n","    def load_model(self, path):\n","        self.saver.restore(self.sess, path)\n","        print(\n","            \"Load prev model\"\n","          )\n","\n","    def act(self, state):\n","        if random.random() <= self.epsilon:\n","            return random.randrange(self.action_size)\n","        return np.argmax(\n","            self.sess.run(self.logits, feed_dict={self.X: state})[0]\n","        )\n","    def buy_act(self, state):\n","        return np.argmax(\n","            self.sess.run(self.logits, feed_dict={self.X: state})[0]\n","        )\n","\n","    def get_state(self, t):\n","        window_size = self.window_size + 1\n","        d = t - window_size + 1\n","        if self.MACD_enable:\n","          block = (\n","              self.train_MACD[d : t + 1]\n","              if d >= 0\n","              else -d * [self.train_MACD[0]] + self.train_MACD[0 : t + 1]\n","          )\n","        else:\n","          block = (\n","              self.trend[d : t + 1]\n","              if d >= 0\n","              else -d * [self.trend[0]] + self.trend[0 : t + 1]\n","          )\n","        res = []\n","        for i in range(window_size - 1):\n","            res.append(block[i + 1] - block[i])\n","        return np.array([res])\n","\n","    def get_buy_state(self, t):\n","        window_size = self.window_size + 1\n","        d = t - window_size + 1\n","        if self.MACD_enable:\n","          block = (\n","              self.buy_MACD[d : t + 1]\n","              if d >= 0\n","              else -d * [self.buy_MACD[0]] + self.buy_MACD[0 : t + 1]\n","          )\n","        else:\n","          block = (\n","              self.buy_trend[d : t + 1]\n","              if d >= 0\n","              else -d * [self.buy_trend[0]] + self.buy_trend[0 : t + 1]\n","          )\n","        res = []\n","        for i in range(window_size - 1):\n","            res.append(block[i + 1] - block[i])\n","        return np.array([res])\n","\n","    def replay(self, batch_size):\n","        mini_batch = []\n","        l = len(self.memory)\n","        for i in range(l - batch_size, l):\n","            mini_batch.append(self.memory[i])\n","        replay_size = len(mini_batch)\n","        X = np.empty((replay_size, self.state_size))\n","        Y = np.empty((replay_size, self.action_size))\n","        states = np.array([a[0][0] for a in mini_batch])\n","        new_states = np.array([a[3][0] for a in mini_batch])\n","        Q = self.sess.run(self.logits, feed_dict={self.X: states})\n","        Q_new = self.sess.run(self.logits, feed_dict={self.X: new_states})\n","        for i in range(len(mini_batch)):\n","            state, action, reward, next_state, done = mini_batch[i]\n","            target = Q[i]\n","            target[action] = reward\n","            if not done:\n","                target[action] += self.gamma * np.amax(Q_new[i])\n","            X[i] = state\n","            Y[i] = target\n","        cost, _ = self.sess.run(\n","            [self.cost, self.optimizer], feed_dict={self.X: X, self.Y: Y}\n","        )\n","\n","        if self.epsilon > self.epsilon_min:\n","            self.epsilon *= self.epsilon_decay\n","        return cost\n","\n","    def buy(self, initial_money):\n","        # Simulate\n","        starting_money = initial_money\n","        states_sell = []\n","        states_buy = []\n","        inventory = []\n","        state = self.get_buy_state(0)\n","        holding_inventory = 0\n","\n","\n","        for t in range(0, len(self.buy_trend) - 1, self.skip):\n","            action = self.buy_act(state)\n","            next_state = self.get_buy_state(t + 1)\n","\n","            ### Action == do nothing\n","            if (\n","                action == 0\n","                and holding_inventory > holding_inventory // 10\n","                and self.buy_trend[t] > np.mean(inventory) + 100\n","            ):\n","              act = 1 + len(inventory) // 10\n","              for i in range(act * unit):\n","                bought_price = inventory.pop(0)\n","                initial_money += self.buy_trend[t]\n","                states_sell.append(t)\n","              holding_inventory -= act * unit\n","              try:\n","                invest = ((buy_close[t] - bought_price) / bought_price) * 100\n","              except:\n","                invest = 0\n","              print(\n","                \"day %d, sell %d unit at price %f, investment %f %%, total balance %f,\"\n","                % (t ,act * unit ,buy_close[t], invest, initial_money)\n","              )\n","            ### Action == Buy\n","            elif (\n","                action != 0\n","                and action <= (self.action_size_half)\n","                and initial_money >= action * self.buy_trend[t] * unit\n","                and t < (len(self.buy_trend) - self.half_window)\n","            ):\n","              for i in range(action * unit):\n","                inventory.append(self.buy_trend[t])\n","                states_buy.append(t)\n","                initial_money -= self.buy_trend[t]\n","              holding_inventory += action * unit\n","\n","              print(\n","                \"day %d: buy %d unit at price %f, total balance %f\"\n","                % (t ,action * unit ,self.buy_trend[t], initial_money)\n","              )\n","            ### Action == Sell\n","            elif (\n","                action != self.action_size - 1\n","                and action > ( self.action_size_half )\n","                and holding_inventory >= ( action - self.action_size_half ) * unit\n","                # and self.buy_trend[t] > np.mean(inventory)\n","            ):\n","              act = action - self.action_size_half # 賣出數量\n","              for i in range(act * unit):\n","                bought_price = inventory.pop(0)\n","                initial_money += self.buy_trend[t]\n","                states_sell.append(t)\n","              holding_inventory -= act * unit\n","              try:\n","                invest = ((buy_close[t] - bought_price) / bought_price) * 100\n","              except:\n","                invest = 0\n","\n","              print(\n","                \"day %d, sell %d unit at price %f, investment %f %%, total balance %f,\"\n","                % (t ,act * unit ,buy_close[t], invest, initial_money)\n","              )\n","\n","            state = next_state\n","\n","        print(holding_inventory)\n","        total_gains = initial_money - starting_money + len(inventory) * self.buy_trend[t]\n","        invest = ( total_gains  / starting_money) * 100\n","        return states_buy, states_sell, total_gains, invest\n","\n","\n","    def train(self, iterations, checkpoint, initial_money):\n","        loss = []\n","        for i in range(iterations):\n","            total_profit = 0\n","            inventory = []\n","            state = self.get_state(0)\n","            starting_money = initial_money\n","            holding_inventory = 0\n","            for t in range(0, len(self.trend) - 1, self.skip):\n","                action = self.act(state)\n","                next_state = self.get_state(t + 1)\n","                ### Action == Punish\n","                if (\n","                    action == 0\n","                ):\n","                  starting_money -= 0\n","                ### Action == Buy\n","                elif (\n","                    action != 0\n","                    and action <= (self.action_size_half)\n","                    and starting_money >= action * self.trend[t] * unit\n","                    and t < (len(self.trend) - self.half_window)\n","                ):\n","                    for j in range(action * unit):\n","                      inventory.append(self.trend[t])\n","                    holding_inventory += action * unit\n","                    starting_money -= action * unit * self.trend[t]\n","                ### Action == Sell\n","                elif (\n","                    action != self.action_size - 1\n","                    and action > ( self.action_size_half )\n","                    and holding_inventory >= ( action - self.action_size_half ) * unit\n","                ):\n","                    act = action - self.action_size_half # 賣出數量\n","                    for j in range(act * unit):\n","                      bought_price = inventory.pop(0)\n","                      starting_money += self.trend[t]\n","                    holding_inventory -= act * unit\n","\n","                invest = (starting_money - initial_money) / initial_money\n","                self.memory.append(\n","                    (state, action, invest, next_state, starting_money < initial_money)\n","                )\n","                state = next_state\n","                batch_size = min(self.batch_size, len(self.memory))\n","                cost = self.replay(batch_size)\n","            loss.append(cost)\n","            total_profit = starting_money - initial_money + len(inventory) * self.trend[t]\n","\n","            if (i + 1) % checkpoint == 0:\n","                print(\n","                    \"epoch: %d, total rewards: %f, cost: %f, total money: %f\"\n","                    % (i + 1, total_profit, cost, starting_money + len(inventory) * self.trend[t])\n","                )\n","        ### Plot loss\n","        plt.figure(figsize=(9, 5))\n","        plt.plot(np.squeeze(loss))\n","        plt.ylabel('loss')\n","        plt.xlabel('iterations')\n","        plt.savefig('aa.png')\n","        plt.show()\n","\n"],"metadata":{"id":"fcIG30ifGwaM","executionInfo":{"status":"ok","timestamp":1705327480761,"user_tz":-480,"elapsed":5,"user":{"displayName":"陳柏丞","userId":"03926144741521813207"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["### Initialize\n","\n","train_close = df_train.Close.values.tolist()\n","buy_close = df_test.Close.values.tolist()\n","train_MACD = to_MACD(list(train_close))\n","buy_MACD = to_MACD(list(buy_close))\n","\n","\n","# train_close = train_close[30:]\n","# buy_close = buy_close[30:]\n","# train_MACD = train_MACD[30:]\n","# buy_MACD = buy_MACD[30:]\n","\n","initial_money = 1000000\n","window_size = 30\n","skip = 1\n","batch_size = 32\n","\n","unit = 1\n","\n","agent = Agent(\n","    state_size = window_size,\n","    window_size = window_size,\n","    trend = train_close,\n","    buy_trend = buy_close,\n","    skip = skip,\n","    batch_size = batch_size,\n","    train_MACD = train_MACD,\n","    buy_MACD = buy_MACD,\n","    MACD_enable = 1    #  change MACD_enable to 1 if you want to use MACD\n",")\n","\n","### Train\n","\n","# agent.load_model('/content/drive/MyDrive/Colab Notebooks/project/model/normal/model.ckpt')\n","agent.train(iterations=200, checkpoint=10, initial_money=initial_money)\n","agent.save_model('/content/drive/MyDrive/Colab Notebooks/project/model/normal/model.ckpt')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":759},"id":"WBmqaN535h2T","executionInfo":{"status":"error","timestamp":1705328417321,"user_tz":-480,"elapsed":936565,"user":{"displayName":"陳柏丞","userId":"03926144741521813207"}},"outputId":"b8d81729-168b-41a1-e500-3827f7eceec1"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["需要 65910 次迭代才會使 epsilon 降到 0.01\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-5-21cc803b60cd>:37: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  hidden1 = tf.layers.dense(self.X, 512, activation=tf.nn.relu)\n","<ipython-input-5-21cc803b60cd>:38: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  self.logits = tf.layers.dense(hidden1, self.action_size)\n"]},{"output_type":"stream","name":"stdout","text":["epoch: 10, total rewards: 729009.907715, cost: 4.242275, total money: 1729009.907715\n","epoch: 20, total rewards: 708790.667969, cost: 1.617347, total money: 1708790.667969\n","epoch: 30, total rewards: 214596.977539, cost: 0.979588, total money: 1214596.977539\n","epoch: 40, total rewards: 18889.197266, cost: 0.228837, total money: 1018889.197266\n","epoch: 50, total rewards: 185384.790527, cost: 0.368959, total money: 1185384.790527\n","epoch: 60, total rewards: 202606.926270, cost: 0.114487, total money: 1202606.926270\n","epoch: 70, total rewards: 136843.128418, cost: 0.245866, total money: 1136843.128418\n","epoch: 80, total rewards: 113429.671875, cost: 0.323545, total money: 1113429.671875\n","epoch: 90, total rewards: 102733.324707, cost: 0.548562, total money: 1102733.324707\n","epoch: 100, total rewards: -121510.917969, cost: 0.054297, total money: 878489.082031\n","epoch: 110, total rewards: 100619.682617, cost: 0.566567, total money: 1100619.682617\n","epoch: 120, total rewards: 92480.403809, cost: 0.274416, total money: 1092480.403809\n","epoch: 130, total rewards: 81076.936523, cost: 0.295068, total money: 1081076.936523\n","epoch: 140, total rewards: 117294.930176, cost: 0.444810, total money: 1117294.930176\n","epoch: 150, total rewards: 61410.601074, cost: 0.120165, total money: 1061410.601074\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-229dcb3096bc>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# agent.load_model('/content/drive/MyDrive/Colab Notebooks/project/model/normal/model.ckpt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_money\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_money\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/project/model/normal/model.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-21cc803b60cd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, checkpoint, initial_money)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mtotal_profit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstarting_money\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minitial_money\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minventory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrend\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-21cc803b60cd>\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         cost, _ = self.sess.run(\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    973\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    974\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[0;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1216\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[1;32m   1217\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1396\u001b[0m                            run_metadata)\n\u001b[1;32m   1397\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1400\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1403\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1383\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1386\u001b[0m                                       target_list, run_metadata)\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1476\u001b[0m   def _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1477\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1478\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1479\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m                                             run_metadata)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["### Simulation\n","states_buy, states_sell, total_gains, invest = agent.buy(initial_money=initial_money)\n","\n","\n","### Plot\n","fig = plt.figure(figsize=(15, 5))\n","plt.plot(buy_close, color='r', lw=2.)\n","plt.plot(buy_close, '^', markersize=10, color='m', label='buying signal', markevery=states_buy)\n","plt.plot(buy_close, 'v', markersize=10, color='k', label='selling signal', markevery=states_sell)\n","plt.title('total gains %f, total investment %f%%' % (total_gains, invest))\n","plt.legend()\n","plt.savefig('aaa.png')  # Save the plot as an image\n","plt.show()\n","\n","### Plot\n","# fig2 = plt.figure(figsize=(15, 5))\n","# plt.plot(buy_MACD, color='r', lw=2.)\n","# plt.plot(buy_MACD, '^', markersize=10, color='m', label='buying signal', markevery=states_buy)\n","# plt.plot(buy_MACD, 'v', markersize=10, color='k', label='selling signal', markevery=states_sell)\n","# plt.axhline(y=0, color='gray', linestyle='--', linewidth=2, label='Y=0 line')\n","# plt.legend()\n","# plt.show()\n","\n","\n"],"metadata":{"id":"8__D1hFhCPUF","executionInfo":{"status":"aborted","timestamp":1705328417322,"user_tz":-480,"elapsed":6,"user":{"displayName":"陳柏丞","userId":"03926144741521813207"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### test\n","today_data = df_train.loc[df_train['Date'] == \"2023-12-08\"]\n","\n","if not today_data.empty:\n","    print(today_data)\n","else:\n","    print(\"今天休市\")\n","\n","today = today_data.index.values[0]\n","\n","print(today)\n","\n","## load_state\n","# try :\n","#     tf = open(\"/content/drive/MyDrive/Colab Notebooks/project/record/\" + data_name + \".json\", \"r\")\n","#     prev_datas = json.load(tf)\n","#     states_buy, states_sell, total_gains, invest = agent.buy_test(initial_money=initial_money, today = today,\n","#     path = \"/content/drive/MyDrive/Colab Notebooks/project/record/\" + data_name,\n","#     end = -1, prev_datas = prev_datas )\n","\n","# except :\n","#     states_buy, states_sell, total_gains, invest = agent.buy_test(initial_money=initial_money, today = today,\n","#     path = \"/content/drive/MyDrive/Colab Notebooks/project/record/\" + data_name,\n","#     end = len(agent.buy_trend) // 2, prev_datas = 0 )\n"],"metadata":{"id":"EJqH96liep6O","executionInfo":{"status":"aborted","timestamp":1705328417323,"user_tz":-480,"elapsed":6,"user":{"displayName":"陳柏丞","userId":"03926144741521813207"}}},"execution_count":null,"outputs":[]}]}